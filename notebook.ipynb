{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eccb3123",
   "metadata": {},
   "source": [
    "#   Trabalho Computacional 2. Perceptron Multicamada no problema MNIST\n",
    "\n",
    "> Nome: *Gabriel Martins Silveira de Oliveira*  \n",
    "> Matrícula: 190042656\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e594c4",
   "metadata": {},
   "source": [
    "## Sumário\n",
    "\n",
    "Neste projeto, será realizada a implementação de um modelo Perceptron Multicamadas (MLP), \n",
    "evoluindo a partir do conceito do Perceptron original.  \n",
    "Todas as implementações utilizarão o conjunto de dados \n",
    "(dataset) MNIST, fornecido pela biblioteca PyTorch.\n",
    "\n",
    "Serão exploradas as seguintes configurações e variações do modelo:\n",
    "\n",
    "1.  **MLP com uma Camada Oculta e Otimizador SGD:**\n",
    "    *   Implementação de um Perceptron Multicamadas com uma camada oculta contendo 128 neurônios.\n",
    "    *   Utilização da função de ativação Sigmoide (logística) na camada oculta.\n",
    "    *   Utilização da função de ativação Softmax na camada de saída (adequada para classificação multiclasse como o MNIST).\n",
    "    *   Otimização realizada por meio da Descida de Gradiente Estocástico (SGD).\n",
    "\n",
    "2.  **Otimizador Adam:**\n",
    "    *   Substituição do otimizador SGD pelo Adam, que ajusta adaptativamente a taxa de aprendizado para cada parâmetro do modelo, visando uma convergência potencialmente mais eficiente.\n",
    "\n",
    "3.  **Função de Ativação ReLU:**\n",
    "    *   Substituição da função de ativação Sigmoide pela ReLU (Rectified Linear Unit) na(s) camada(s) oculta(s), analisando seu impacto no desempenho e na mitigação do problema de desaparecimento do gradiente.\n",
    "\n",
    "4.  **Exploração de Arquiteturas Maiores:**\n",
    "    *   Avaliação do impacto do aumento da capacidade do modelo através de:\n",
    "        *   Um MLP com uma única camada oculta contendo 256 neurônios.\n",
    "        *   Um MLP com duas camadas ocultas, cada uma contendo 128 neurônios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37348db",
   "metadata": {},
   "source": [
    "## Entendendo O DataSet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8d70400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe0795",
   "metadata": {},
   "source": [
    "Estarei salvando tudo em [`./data`](./data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f059956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=True, num_workers=4, # Tentei Melhorar a performance\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=1000, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63384d13",
   "metadata": {},
   "source": [
    "Apos carregar o data set podemos analizar suas dimenções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9ec7dbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 10\n",
      "0 - zero\n",
      "1 - one\n",
      "2 - two\n",
      "3 - three\n",
      "4 - four\n",
      "5 - five\n",
      "6 - six\n",
      "7 - seven\n",
      "8 - eight\n",
      "9 - nine\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classes: {test_dataset.classes.__len__()}\",*test_dataset.classes, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17baa0",
   "metadata": {},
   "source": [
    "Podemos ver que estamos classificando 10 diferentes classes.  \n",
    "Aparentemente estamos classificando números. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c2c23fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([64, 1, 28, 28])\n",
      "y.shape=torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "examples = enumerate(train_loader)\n",
    "batch_idx, (x, y) = next(examples)\n",
    "\n",
    "print(f\"{x.shape=}\", f\"{y.shape=}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4412a",
   "metadata": {},
   "source": [
    "Temos um tensor de `batch_size` (64) exemplos, 1 canal e dois canais de dimenção 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86142b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4242, -0.4242],\n",
       "        [-0.4242, -0.4242]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :2, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c4b1c",
   "metadata": {},
   "source": [
    "Ambos canais de 28 por 28 mostram a intensidade da luz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "67015e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(8, 8))\n",
    "for ax, i in zip(ax.flatten(), range(9)):\n",
    "    ax.imshow(x[i][0], cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {y[i]}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a886c",
   "metadata": {},
   "source": [
    "Confirmamos que realmente estamos classificando números."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17efcf",
   "metadata": {},
   "source": [
    "## Funções a serem utilizadas\n",
    "\n",
    "Vamos definir algumas funções que utilizaremos ao longo do codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dfcfba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import Optimizer, SGD\n",
    "from torch import Tensor, device, no_grad\n",
    "from torch.nn import Module, Sequential, Flatten, Linear, Sigmoid, CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfc85c0",
   "metadata": {},
   "source": [
    "### Modelo Base\n",
    "\n",
    "Uma vez que estaremos lidando com diferentes casos sera conveniente \n",
    "definir um modelo base em que alteramos funções basicas e assim podemos analizar modelos diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "95a4d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.train_data = train_loader\n",
    "        self.eval_data = test_loader\n",
    "        self.device = device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def get_optimizer(self) -> Optimizer:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_loss_fn(self) -> Module:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d5aa5",
   "metadata": {},
   "source": [
    "### Função de treinamento\n",
    "\n",
    "Treinamento do modelo dentro de uma época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb999193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: BaseModel,\n",
    "    train_losses: list[float],\n",
    "):\n",
    "    data_loader = model.train_data\n",
    "    loss_fn = model.get_loss_fn()\n",
    "    optmizer = model.get_optimizer()\n",
    "    device = model.device\n",
    "    model.train()\n",
    "    current_loss = 0\n",
    "    for data, target in data_loader:\n",
    "        # Pode comentar, gosto de type hint\n",
    "        data: Tensor = data\n",
    "        target: Tensor = target\n",
    "\n",
    "        data, target = data.to(device=device), target.to(\n",
    "            device=device\n",
    "        )  # Quero rodar na GPU\n",
    "\n",
    "        optmizer.zero_grad(set_to_none=True)\n",
    "        logits = model(data)\n",
    "        loss: Tensor = loss_fn(logits, target)\n",
    "        loss.backward()\n",
    "        optmizer.step()\n",
    "        current_loss += loss.item()\n",
    "\n",
    "    avg_loss = current_loss / len(data_loader)\n",
    "    train_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77ed0e",
   "metadata": {},
   "source": [
    "### Função de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "551b92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(\n",
    "    model: BaseModel,\n",
    "    eval_losses: list[float],\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    data_loader = model.eval_data\n",
    "    loss_fn = model.get_loss_fn()\n",
    "    device = model.device\n",
    "    model.eval()\n",
    "    with no_grad():\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        current_loss = 0\n",
    "        for data, target in data_loader:\n",
    "            # Pode comentar, gosto de type hint\n",
    "            data: Tensor = data\n",
    "            target: Tensor = target\n",
    "\n",
    "            data, target = data.to(device=device), target.to(\n",
    "                device=device\n",
    "            )  # Quero rodar na GPU\n",
    "\n",
    "            logits: Tensor = model(data)\n",
    "            loss: Tensor = loss_fn(logits, target)\n",
    "            current_loss += loss.item()\n",
    "\n",
    "            pred = logits.argmax(dim=1) # Predição sera o maior das 10 classes\n",
    "            \n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_targets.append(target.cpu().numpy())\n",
    "\n",
    "        avg_loss = current_loss / len(data_loader)\n",
    "        eval_losses.append(avg_loss)\n",
    "\n",
    "        return np.concatenate(all_targets), np.concatenate(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa4f667",
   "metadata": {},
   "source": [
    "### Função de acuracia\n",
    "\n",
    "A função de acuracia sera definida pela quantidade de cassos classificados corretamente\n",
    "sobre o total de casos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6f124c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y: np.ndarray, pred: np.ndarray, accuracies: list):\n",
    "    \"\"\"Pega a Acuracia.\n",
    "    Necessário alimentar com todo o vetor de treinamento.\n",
    "\n",
    "    Args:\n",
    "        y (Tensor): Valores verdadeiros\n",
    "        pred (Tensor): Predição\n",
    "    \"\"\"\n",
    "\n",
    "    correct_predictions = np.sum(y == pred)\n",
    "    total_predictions = len(y)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac2ddf",
   "metadata": {},
   "source": [
    "### Função de Final \n",
    "\n",
    "Aqui Vamos fazer um analize de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4403fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def get_info(model: BaseModel, num_epoches: int):\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # For storing the final true and predicted values for confusion matrix\n",
    "    final_targets = None\n",
    "    final_preds = None\n",
    "\n",
    "    print(f\"Training on device: {model.device}\")\n",
    "\n",
    "    # --- Matplotlib Setup for Live Plotting ---\n",
    "    plt.ion()  # Turn on interactive mode\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6)) # (width, height)\n",
    "\n",
    "    # Initial setup for Loss Plot (ax1)\n",
    "    ax1.set_title(\"Perda Média por Época\")\n",
    "    ax1.set_xlabel(\"Época\")\n",
    "    ax1.set_ylabel(\"Perda\")\n",
    "    ax1.set_xlim(0.5, num_epoches + 0.5) # Adjusted for better epoch 1 visibility\n",
    "    # Initial y_lim, will be adjusted dynamically\n",
    "    min_loss_display = 0\n",
    "    max_loss_display = 2.5 # A common starting point for CE loss\n",
    "    ax1.set_ylim(min_loss_display, max_loss_display)\n",
    "\n",
    "\n",
    "    # Initial setup for Accuracy Plot (ax2)\n",
    "    ax2.set_title(\"Acurácia de Validação por Época\")\n",
    "    ax2.set_xlabel(\"Época\")\n",
    "    ax2.set_ylabel(\"Acurácia\")\n",
    "    ax2.set_xlim(0.5, num_epoches + 0.5) # Adjusted\n",
    "    ax2.set_ylim(0, 1.05) # Accuracy is between 0 and 1\n",
    "\n",
    "    # Line objects for updating data later (optional, but good for efficiency)\n",
    "    # If not using this, cla() and replotting is fine as in your example\n",
    "    line_train_loss, = ax1.plot([], [], 'r-o', label=\"Perda Treinamento\")\n",
    "    line_val_loss, = ax1.plot([], [], 'b-o', label=\"Perda Validação\")\n",
    "    line_accuracy, = ax2.plot([], [], 'g-o', label=\"Acurácia Validação\")\n",
    "    \n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2.legend(loc='lower right')\n",
    "    # --- End Matplotlib Setup ---\n",
    "\n",
    "    for epoche in range(1, num_epoches + 1):\n",
    "        epoch_list = list(range(1, epoche + 1)) # x-axis for plots\n",
    "        print(f\"--- Época: {epoche}/{num_epoches} ---\")\n",
    "\n",
    "        train(model=model, train_losses=train_losses)\n",
    "        # Store the latest validation results for confusion matrix\n",
    "        final_targets, final_preds = val(model=model, eval_losses=eval_losses)\n",
    "        get_acc(y=final_targets, pred=final_preds, accuracies=accuracies)\n",
    "\n",
    "        print(\n",
    "            f\"  Train loss: {train_losses[-1]:.4f}\",\n",
    "            f\"  Val loss: {eval_losses[-1]:.4f}\",\n",
    "            f\"  Val Accuracy: {accuracies[-1]:.4f}\",\n",
    "            sep=\"\\n\",\n",
    "        )\n",
    "\n",
    "        # --- Live Plot Update ---\n",
    "        # Update Loss Plot (ax1)\n",
    "        line_train_loss.set_data(epoch_list, train_losses)\n",
    "        line_val_loss.set_data(epoch_list, eval_losses)\n",
    "        \n",
    "        # Dynamically adjust Y-axis for loss plot\n",
    "        if train_losses or eval_losses: # Check if lists are not empty\n",
    "            current_max_loss = 0\n",
    "            if train_losses: current_max_loss = max(current_max_loss, max(train_losses))\n",
    "            if eval_losses: current_max_loss = max(current_max_loss, max(eval_losses))\n",
    "            max_loss_display = max(max_loss_display, current_max_loss * 1.1) # Keep expanding if needed\n",
    "            \n",
    "            current_min_loss = float('inf')\n",
    "            if train_losses: current_min_loss = min(current_min_loss, min(train_losses))\n",
    "            if eval_losses: current_min_loss = min(current_min_loss, min(eval_losses))\n",
    "            min_loss_display = min(min_loss_display, current_min_loss * 0.9) if current_min_loss > 0 else 0\n",
    "\n",
    "            ax1.set_ylim(min_loss_display, max_loss_display)\n",
    "\n",
    "\n",
    "        # Update Accuracy Plot (ax2)\n",
    "        line_accuracy.set_data(epoch_list, accuracies)\n",
    "        \n",
    "        # Redraw the figure\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        plt.pause(0.1)  # Pause allows the plot to update\n",
    "        # --- End Live Plot Update ---\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n",
    "\n",
    "    # --- Plot Finalization ---\n",
    "    plt.ioff() # Turn off interactive mode\n",
    "    ax1.legend() # Ensure legends are there on the final static plot\n",
    "    ax2.legend()\n",
    "    plt.show() # Display the final plot and keep it open\n",
    "    # --- End Plot Finalization ---\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    if final_targets is not None and final_preds is not None:\n",
    "        print(\"\\n--- Confusion Matrix (sobre o último conjunto de validação) ---\")\n",
    "        cm = confusion_matrix(final_targets, final_preds)\n",
    "        cm_df = pd.DataFrame(\n",
    "            cm,\n",
    "            index=[f\"True_{i}\" for i in range(10)], # Assuming 10 classes for MNIST\n",
    "            columns=[f\"Pred_{i}\" for i in range(10)]\n",
    "        )\n",
    "        print(cm_df)\n",
    "    else:\n",
    "        print(\"\\nNão foi possível gerar a matriz de confusão (sem dados de validação).\")\n",
    "    # --- End Confusion Matrix ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9f5a3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output \n",
    "\n",
    "def get_info(model: BaseModel, num_epoches: int):\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    final_targets = None\n",
    "    final_preds = None\n",
    "\n",
    "    # Initial print statement (will appear once above the updating plot)\n",
    "    print(f\"Starting training on device: {model.device} for {num_epoches} epochs.\")\n",
    "\n",
    "    # --- Matplotlib Setup ---\n",
    "    # No plt.ion() needed for this Jupyter approach\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6)) # (width, height)\n",
    "\n",
    "    # Setup for Loss Plot (ax1)\n",
    "    ax1.set_title(\"Perda Média por Época\")\n",
    "    ax1.set_xlabel(\"Época\")\n",
    "    ax1.set_ylabel(\"Perda\")\n",
    "    ax1.set_xlim(0.5, num_epoches + 0.5)\n",
    "    # Dynamic Y-limits for loss, initialize them\n",
    "    overall_min_loss = float('inf')\n",
    "    overall_max_loss = float('-inf')\n",
    "    ax1.set_ylim(0, 2.5) # Initial sensible default\n",
    "    line_train_loss, = ax1.plot([], [], 'r-o', label=\"Perda Treinamento\")\n",
    "    line_val_loss, = ax1.plot([], [], 'b-o', label=\"Perda Validação\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    # Setup for Accuracy Plot (ax2)\n",
    "    ax2.set_title(\"Acurácia de Validação por Época\")\n",
    "    ax2.set_xlabel(\"Época\")\n",
    "    ax2.set_ylabel(\"Acurácia\")\n",
    "    ax2.set_xlim(0.5, num_epoches + 0.5)\n",
    "    ax2.set_ylim(-0.05, 1.05) # Fixed Y-limits for accuracy (0-1 range with padding)\n",
    "    line_accuracy, = ax2.plot([], [], 'g-o', label=\"Acurácia Validação\")\n",
    "    ax2.legend(loc='lower right')\n",
    "    \n",
    "    plt.tight_layout() # Adjust layout to prevent overlap of titles/labels\n",
    "\n",
    "    for epoche in range(1, num_epoches + 1):\n",
    "        epoch_list = list(range(1, epoche + 1)) # x-axis for plots\n",
    "\n",
    "        # --- Training and Validation ---\n",
    "        train(model=model, train_losses=train_losses)\n",
    "        final_targets, final_preds = val(model=model, eval_losses=eval_losses)\n",
    "        get_acc(y=final_targets, pred=final_preds, accuracies=accuracies)\n",
    "\n",
    "        # --- Update Plot Data ---\n",
    "        line_train_loss.set_data(epoch_list, train_losses)\n",
    "        line_val_loss.set_data(epoch_list, eval_losses)\n",
    "        \n",
    "        # Dynamically adjust Y-axis for loss plot (ax1)\n",
    "        if train_losses:\n",
    "            overall_min_loss = min(overall_min_loss, min(train_losses))\n",
    "            overall_max_loss = max(overall_max_loss, max(train_losses))\n",
    "        if eval_losses:\n",
    "            overall_min_loss = min(overall_min_loss, min(eval_losses))\n",
    "            overall_max_loss = max(overall_max_loss, max(eval_losses))\n",
    "\n",
    "        # Set Y Lim for loss plot, ensuring valid range\n",
    "        display_min_y_loss = max(0, overall_min_loss * 0.9) if overall_min_loss != float('inf') else 0\n",
    "        display_max_y_loss = overall_max_loss * 1.1 if overall_max_loss != float('-inf') else ax1.get_ylim()[1]\n",
    "        if display_min_y_loss >= display_max_y_loss : display_max_y_loss = display_min_y_loss + 0.1 # Ensure max > min\n",
    "        ax1.set_ylim(display_min_y_loss, display_max_y_loss)\n",
    "\n",
    "        # Update Accuracy Plot (ax2) - Y limits are fixed, just update data\n",
    "        line_accuracy.set_data(epoch_list, accuracies)\n",
    "        \n",
    "        # --- Jupyter Live Update ---\n",
    "        clear_output(wait=True) # Clear the previous output of the cell\n",
    "        \n",
    "        # Print current epoch's stats\n",
    "        print(f\"--- Época: {epoche}/{num_epoches} ---\")\n",
    "        print(\n",
    "            f\"  Train loss: {train_losses[-1]:.4f}\",\n",
    "            f\"  Val loss: {eval_losses[-1]:.4f}\",\n",
    "            f\"  Val Accuracy: {accuracies[-1]:.4f}\",\n",
    "            sep=\"\\n\",\n",
    "        )\n",
    "        \n",
    "        display(fig) # Display the updated figure in the cell\n",
    "        # --- End Jupyter Live Update ---\n",
    "\n",
    "    # The last plot and text will remain in the cell output after the loop.\n",
    "    # No plt.ioff() or final plt.show() is strictly needed for this pattern.\n",
    "    # However, closing the figure object is good practice if you might re-run\n",
    "    # this function multiple times to avoid accumulating figure objects in memory.\n",
    "    # If you want the plot to *disappear* after this cell runs, then call plt.close(fig) here.\n",
    "    # If you want it to *stay*, don't call plt.close(fig) immediately.\n",
    "\n",
    "    print(\"\\nTraining finished.\") # This will print below the final plot\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    if final_targets is not None and final_preds is not None:\n",
    "        print(\"\\n--- Confusion Matrix (sobre o último conjunto de validação) ---\")\n",
    "        cm = confusion_matrix(final_targets, final_preds)\n",
    "        # Assuming 10 classes for MNIST (0-9)\n",
    "        class_names = [str(i) for i in range(10)] \n",
    "        cm_df = pd.DataFrame(\n",
    "            cm,\n",
    "            index=[f\"True_{name}\" for name in class_names],\n",
    "            columns=[f\"Pred_{name}\" for name in class_names]\n",
    "        )\n",
    "        print(cm_df)\n",
    "    else:\n",
    "        print(\"\\nNão foi possível gerar a matriz de confusão (sem dados de validação).\")\n",
    "    \n",
    "    # Optional: Close the figure if you are done with it and don't want it to linger\n",
    "    # if you plan to generate more plots later or re-run.\n",
    "    # If you want the plot to stay visible in the notebook output, you might omit this,\n",
    "    # or rely on Jupyter's management / %matplotlib magic behavior.\n",
    "    # For this clear_output/display pattern, the plot will persist in the output cell\n",
    "    # even if closed here, because display() creates a representation.\n",
    "    # plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b36ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset \n",
    "\n",
    "# MNIST normalization constants (define these globally or pass them around)\n",
    "MNIST_MEAN = (0.1307,)\n",
    "MNIST_STD = (0.3081,)\n",
    "\n",
    "# --- Helper function to unnormalize an image tensor (from your code) ---\n",
    "def unnormalize_image(tensor_image, mean, std):\n",
    "    \"\"\"Unnormalizes a tensor image.\"\"\"\n",
    "    unnormalized_tensor = tensor_image.clone() # Clone to avoid modifying original\n",
    "    # Iterate over channels. For MNIST, C=1, so this loop runs once.\n",
    "    # t will be the [H,W] tensor, m and s will be the scalar mean/std.\n",
    "    for t, m, s in zip(unnormalized_tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return unnormalized_tensor\n",
    "\n",
    "# --- Function to update live metrics plot ---\n",
    "def update_live_metrics_plot(\n",
    "    ax1: plt.Axes,\n",
    "    ax2: plt.Axes,\n",
    "    line_train_loss: plt.Line2D,\n",
    "    line_val_loss: plt.Line2D,\n",
    "    line_accuracy: plt.Line2D,\n",
    "    epoch_list: list[int],\n",
    "    train_losses: list[float],\n",
    "    eval_losses: list[float],\n",
    "    accuracies: list[float],\n",
    "    current_overall_min_loss: float,\n",
    "    current_overall_max_loss: float\n",
    "):\n",
    "    \"\"\"Updates the data and y-limits for the live metrics plot.\"\"\"\n",
    "    line_train_loss.set_data(epoch_list, train_losses)\n",
    "    line_val_loss.set_data(epoch_list, eval_losses)\n",
    "    line_accuracy.set_data(epoch_list, accuracies)\n",
    "\n",
    "    # Dynamically adjust Y-axis for loss plot (ax1)\n",
    "    display_min_y_loss = max(0, current_overall_min_loss * 0.9) if current_overall_min_loss != float('inf') else 0\n",
    "    display_max_y_loss = current_overall_max_loss * 1.1 if current_overall_max_loss != float('-inf') else ax1.get_ylim()[1]\n",
    "    \n",
    "    if display_min_y_loss >= display_max_y_loss: # Ensure max > min\n",
    "        display_max_y_loss = display_min_y_loss + 0.1 \n",
    "    ax1.set_ylim(display_min_y_loss, display_max_y_loss)\n",
    "    # ax2 y-limits (accuracy) are typically fixed, set during initialization.\n",
    "\n",
    "# --- Function to plot misclassified examples ---\n",
    "def plot_misclassified_examples(\n",
    "    targets: np.ndarray,\n",
    "    preds: np.ndarray,\n",
    "    dataset: Dataset, # The torchvision.datasets.MNIST object\n",
    "    num_to_show: int = 9,\n",
    "    img_mean: tuple = MNIST_MEAN, # Use global MNIST_MEAN/STD by default\n",
    "    img_std: tuple = MNIST_STD\n",
    "):\n",
    "    \"\"\"Plots a grid of misclassified examples from the given dataset.\"\"\"\n",
    "    misclassified_indices = np.where(targets != preds)[0]\n",
    "    actual_num_to_show = min(len(misclassified_indices), num_to_show)\n",
    "\n",
    "    if actual_num_to_show > 0:\n",
    "        print(f\"\\n--- {actual_num_to_show} Exemplos de Classificações Incorretas ---\")\n",
    "        \n",
    "        cols = 3\n",
    "        rows = (actual_num_to_show + cols - 1) // cols # Calculate rows needed\n",
    "        \n",
    "        fig_errors, axes = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 3))\n",
    "        # Handle the case where subplots returns a single Axes object (not an array)\n",
    "        if actual_num_to_show == 1:\n",
    "            axes = np.array([axes]) # Make it an array of one Axes\n",
    "        axes = axes.flatten() # Now flatten works for single or multiple axes\n",
    "\n",
    "        for i in range(actual_num_to_show):\n",
    "            idx_in_dataset = misclassified_indices[i]\n",
    "            \n",
    "            # Get the original image tensor and true label from the dataset\n",
    "            img_tensor, true_label_from_ds = dataset[idx_in_dataset]\n",
    "            \n",
    "            # Unnormalize the image for display (ensure tensor is on CPU)\n",
    "            img_unnorm = unnormalize_image(img_tensor.cpu(), img_mean, img_std)\n",
    "\n",
    "            pred_label = preds[idx_in_dataset]\n",
    "            true_label = targets[idx_in_dataset] # Should match true_label_from_ds\n",
    "\n",
    "            ax = axes[i]\n",
    "            # Squeeze to remove channel dim for grayscale, convert to numpy\n",
    "            ax.imshow(img_unnorm.squeeze().numpy(), cmap='gray')\n",
    "            ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "            ax.axis('off')\n",
    "        \n",
    "        # Hide any unused subplots if num_to_show < rows*cols\n",
    "        for j in range(actual_num_to_show, len(axes)):\n",
    "            axes[j].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show() # Show this new figure for errors\n",
    "    else:\n",
    "        print(\"\\nParabéns! Nenhuma classificação incorreta encontrada no último conjunto de validação!\")\n",
    "\n",
    "# --- Main Info Gathering Function (Refactored) ---\n",
    "def get_info(model: BaseModel, num_epoches: int): # Removed val_dataset_for_plotting\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    # Store targets/preds from the *last* validation run for final analysis\n",
    "    final_targets_epoch = None\n",
    "    final_preds_epoch = None\n",
    "\n",
    "    print(f\"Starting training on device: {model.device} for {num_epoches} epochs.\")\n",
    "\n",
    "    # --- Matplotlib Setup for Live Metrics ---\n",
    "    fig_metrics, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    ax1.set_title(\"Perda Média por Época\")\n",
    "    ax1.set_xlabel(\"Época\")\n",
    "    ax1.set_ylabel(\"Perda\")\n",
    "    ax1.set_xlim(0.5, num_epoches + 0.5)\n",
    "    # Trackers for dynamic Y-axis scaling of loss plot\n",
    "    overall_min_loss_tracker, overall_max_loss_tracker = float('inf'), float('-inf')\n",
    "    ax1.set_ylim(0, 2.5) # Initial sensible default for loss\n",
    "    line_train_loss, = ax1.plot([], [], 'r-o', label=\"Perda Treinamento\")\n",
    "    line_val_loss, = ax1.plot([], [], 'b-o', label=\"Perda Validação\")\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    ax2.set_title(\"Acurácia de Validação por Época\")\n",
    "    ax2.set_xlabel(\"Época\")\n",
    "    ax2.set_ylabel(\"Acurácia\")\n",
    "    ax2.set_xlim(0.5, num_epoches + 0.5)\n",
    "    ax2.set_ylim(-0.05, 1.05) # Fixed Y-limits for accuracy\n",
    "    line_accuracy, = ax2.plot([], [], 'g-o', label=\"Acurácia Validação\")\n",
    "    ax2.legend(loc='lower right')\n",
    "    \n",
    "    plt.tight_layout() # Adjust layout for the metrics plot\n",
    "\n",
    "    for epoche in range(1, num_epoches + 1):\n",
    "        epoch_list = list(range(1, epoche + 1)) # X-axis values for plots\n",
    "        \n",
    "        # --- Training and Validation ---\n",
    "        train(model=model, train_losses=train_losses)\n",
    "        # `val` returns targets and predictions for the current epoch\n",
    "        final_targets_epoch, final_preds_epoch = val(model=model, eval_losses=eval_losses)\n",
    "        get_acc(y=final_targets_epoch, pred=final_preds_epoch, accuracies=accuracies)\n",
    "\n",
    "        # --- Update Overall Loss Trackers ---\n",
    "        if train_losses: # Check if list is not empty\n",
    "            overall_min_loss_tracker = min(overall_min_loss_tracker, min(train_losses))\n",
    "            overall_max_loss_tracker = max(overall_max_loss_tracker, max(train_losses))\n",
    "        if eval_losses: # Check if list is not empty\n",
    "            overall_min_loss_tracker = min(overall_min_loss_tracker, min(eval_losses))\n",
    "            overall_max_loss_tracker = max(overall_max_loss_tracker, max(eval_losses))\n",
    "\n",
    "        # --- Update Live Plot ---\n",
    "        update_live_metrics_plot(\n",
    "            ax1, ax2, line_train_loss, line_val_loss, line_accuracy,\n",
    "            epoch_list, train_losses, eval_losses, accuracies,\n",
    "            overall_min_loss_tracker, overall_max_loss_tracker\n",
    "        )\n",
    "        \n",
    "        # --- Jupyter Live Update: Clear previous output, print new stats, display updated figure ---\n",
    "        clear_output(wait=True)\n",
    "        print(f\"--- Época: {epoche}/{num_epoches} ---\")\n",
    "        print(\n",
    "            f\"  Train loss: {train_losses[-1]:.4f}\",\n",
    "            f\"  Val loss: {eval_losses[-1]:.4f}\",\n",
    "            f\"  Val Accuracy: {accuracies[-1]:.4f}\",\n",
    "            sep=\"\\n\",\n",
    "        )\n",
    "        display(fig_metrics) # Display the updated metrics plot\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n",
    "    # The metrics plot (fig_metrics) will remain in the cell output.\n",
    "    # If you need to close it explicitly (e.g., if calling get_info in a loop), use:\n",
    "    # plt.close(fig_metrics) \n",
    "\n",
    "    # --- Post-Training Analysis (Confusion Matrix & Misclassified Examples) ---\n",
    "    if final_targets_epoch is not None and final_preds_epoch is not None:\n",
    "        # Confusion Matrix\n",
    "        print(\"\\n--- Confusion Matrix (sobre o último conjunto de validação) ---\")\n",
    "        cm = confusion_matrix(final_targets_epoch, final_preds_epoch)\n",
    "        class_names = [str(i) for i in range(10)] # Assuming 10 classes for MNIST\n",
    "        cm_df = pd.DataFrame(\n",
    "            cm,\n",
    "            index=[f\"True_{n}\" for n in class_names],\n",
    "            columns=[f\"Pred_{n}\" for n in class_names]\n",
    "        )\n",
    "        print(cm_df)\n",
    "\n",
    "        # Plot Misclassified Images\n",
    "        # Access the dataset from the model's DataLoader\n",
    "        if hasattr(model.eval_data, 'dataset') and isinstance(model.eval_data.dataset, Dataset):\n",
    "            validation_dataset = model.eval_data.dataset\n",
    "            plot_misclassified_examples(\n",
    "                targets=final_targets_epoch,\n",
    "                preds=final_preds_epoch,\n",
    "                dataset=validation_dataset, # Pass the actual dataset object\n",
    "                num_to_show=9\n",
    "                # img_mean and img_std will use defaults MNIST_MEAN, MNIST_STD\n",
    "            )\n",
    "        else:\n",
    "            print(\"\\nAlerta: Não foi possível obter o `dataset` do `model.eval_data`.\")\n",
    "            print(\"Certifique-se que `model.eval_data.dataset` é um objeto `torch.utils.data.Dataset` válido.\")\n",
    "    else:\n",
    "        print(\"\\nNão foi possível gerar a matriz de confusão ou mostrar erros (sem dados de validação finais).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "257fc1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(model: BaseModel, num_epoches: int):\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoche in range(1, num_epoches + 1):\n",
    "        print(f\"--- Época: {epoche}/{num_epoches} ---\")\n",
    "\n",
    "        train(model=model, train_losses=train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c014efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Modelo1(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Sequential(\n",
    "            Flatten(),\n",
    "            Linear(28 * 28, 128),\n",
    "            Sigmoid(),\n",
    "            Linear(128, 10),\n",
    "        )\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def get_optimizer(self) -> Optimizer:\n",
    "        return SGD(self.parameters(), lr=0.1, momentum=0.9)\n",
    "    \n",
    "    def get_loss_fn(self) -> Module:\n",
    "        return CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f5b4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Época: 1/5 ---\n",
      "--- Época: 2/5 ---\n",
      "--- Época: 3/5 ---\n",
      "--- Época: 4/5 ---\n",
      "--- Época: 5/5 ---\n"
     ]
    }
   ],
   "source": [
    "model = Modelo1()\n",
    "\n",
    "get_info(model=model, num_epoches=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
